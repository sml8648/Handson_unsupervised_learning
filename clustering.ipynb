{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clustering.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPB58wVadfSnWkdvG9A6O/h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sml8648/Handson_unsupervised_learning/blob/main/clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastcluster==1.1.26"
      ],
      "metadata": {
        "id": "eQ3FcLIgc8p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hdbscan==0.8.27"
      ],
      "metadata": {
        "id": "g58W8m-Uc-MV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYUgeCvmcaHW"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "'''Main'''\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, time, pickle, gzip\n",
        "import datetime\n",
        "\n",
        "'''Data Prep'''\n",
        "from sklearn import preprocessing as pp \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "\n",
        "'''Data Viz'''\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "color = sns.color_palette()\n",
        "%matplotlib inline\n",
        "\n",
        "'''Algoirthm'''\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "import fastcluster\n",
        "from scipy.cluster.hierarchy import dendrogram, cophenet, fcluster\n",
        "from scipy.spatial.distance import pdist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "vDqS5jS6doX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2)\n",
        "X_train = X_train.reshape(48000,-1)\n",
        "X_validation = X_validation.reshape(12000,-1)\n",
        "X_test = X_test.reshape(10000,-1)"
      ],
      "metadata": {
        "id": "uNp1frrfdrRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of X_train: \", X_train.shape)\n",
        "print(\"Shape of y_train: \", y_train.shape)\n",
        "print(\"Shape of X_validation: \", X_validation.shape)\n",
        "print(\"Shape of y_validation: \", y_validation.shape)\n",
        "print(\"Shape of X_test: \", X_test.shape)\n",
        "print(\"Shape of y_test: \", y_test.shape)"
      ],
      "metadata": {
        "id": "Ua4axJazd1_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_index = range(0,len(X_train))\n",
        "validation_index = range(len(X_train), \\\n",
        "                         len(X_train)+len(X_validation))\n",
        "test_index = range(len(X_train)+len(X_validation), \\\n",
        "                   len(X_train)+len(X_validation)+len(X_test))\n",
        "\n",
        "X_train = pd.DataFrame(data=X_train,index=train_index)\n",
        "y_train = pd.Series(data=y_train,index=train_index)\n",
        "\n",
        "X_validation = pd.DataFrame(data=X_validation,index=validation_index)\n",
        "y_validation = pd.Series(data=y_validation,index=validation_index)\n",
        "\n",
        "X_test = pd.DataFrame(data=X_test,index=test_index)\n",
        "y_test = pd.Series(data=y_test,index=test_index)"
      ],
      "metadata": {
        "id": "NObeZQn1eZlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dimensionality Reduction"
      ],
      "metadata": {
        "id": "oo0G7UM0d8PC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "n_components = 784\n",
        "whiten = False\n",
        "random_state = 2018\n",
        "\n",
        "pca = PCA(n_components=n_components, whiten=whiten, random_state=random_state)\n",
        "\n",
        "X_train_PCA = pca.fit_transform(X_train)\n",
        "X_train_PCA = pd.DataFrame(data=X_train_PCA, index=train_index)"
      ],
      "metadata": {
        "id": "wIKVS6LDd-as"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-means\n",
        "<h2> Inertia"
      ],
      "metadata": {
        "id": "hgVIY7WJeqt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "n_clusters = 10\n",
        "n_init = 10\n",
        "max_iter = 300\n",
        "tol = 0.0001\n",
        "random_state = 2018\n",
        "\n",
        "kMeans_inertia = pd.DataFrame(data=[], index=range(2,21), columns=['inertia'])\n",
        "\n",
        "for n_clusters in range(2,21):\n",
        "    kmeans = KMeans(n_clusters=n_clusters, n_init=n_init, max_iter=max_iter, tol=tol, random_state=random_state)\n",
        "\n",
        "    cutoff = 99\n",
        "    kmeans.fit(X_train_PCA.loc[:,0:cutoff])\n",
        "    kMeans_inertia.loc[n_clusters] = kmeans.inertia_"
      ],
      "metadata": {
        "id": "-PyisjkPetNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kMeans_inertia.plot()"
      ],
      "metadata": {
        "id": "GQZrhOMPfX3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy"
      ],
      "metadata": {
        "id": "0FRQhY_B6Z76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyzeCluster(clusterDF, labelsDF):\n",
        "    countByCluster = \\\n",
        "        pd.DataFrame(data=clusterDF['cluster'].value_counts())\n",
        "    countByCluster.reset_index(inplace=True,drop=False)\n",
        "    countByCluster.columns = ['cluster','clusterCount']\n",
        "        \n",
        "    preds = pd.concat([labelsDF,clusterDF], axis=1)\n",
        "    preds.columns = ['trueLabel','cluster']\n",
        "    \n",
        "    countByLabel = pd.DataFrame(data=preds.groupby('trueLabel').count())\n",
        "        \n",
        "    countMostFreq = \\\n",
        "        pd.DataFrame(data=preds.groupby('cluster').agg( \\\n",
        "                        lambda x:x.value_counts().iloc[0]))\n",
        "    countMostFreq.reset_index(inplace=True,drop=False)\n",
        "    countMostFreq.columns = ['cluster','countMostFrequent']\n",
        "    \n",
        "    accuracyDF = countMostFreq.merge(countByCluster, \\\n",
        "                        left_on=\"cluster\",right_on=\"cluster\")\n",
        "    overallAccuracy = accuracyDF.countMostFrequent.sum()/ \\\n",
        "                        accuracyDF.clusterCount.sum()\n",
        "    \n",
        "    accuracyByLabel = accuracyDF.countMostFrequent/ \\\n",
        "                        accuracyDF.clusterCount\n",
        "    \n",
        "    return countByCluster, countByLabel, countMostFreq, \\\n",
        "            accuracyDF, overallAccuracy, accuracyByLabel"
      ],
      "metadata": {
        "id": "g73shBAv6bEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K-means - Accuracy as the number of clusters varies\n",
        "\n",
        "n_clusters = 5\n",
        "n_init = 10\n",
        "max_iter = 300\n",
        "tol = 0.0001\n",
        "random_state = 2018\n",
        "\n",
        "kMeans_inertia = pd.DataFrame(data=[],index=range(2,21),columns=['inertia'])\n",
        "overallAccuracy_kMeansDF = pd.DataFrame(data=[],index=range(2,21),columns=['overallAccuracy'])\n",
        "\n",
        "for n_clusters in range(2,21):\n",
        "    kmeans = KMeans(n_clusters=n_clusters, n_init=n_init, max_iter=max_iter, tol=tol, random_state=random_state)\n",
        "\n",
        "    cutoff = 99\n",
        "    kmeans.fit(X_train_PCA.loc[:,0:cutoff])\n",
        "    kMeans_inertia.loc[n_clusters] = kmeans.inertia_\n",
        "    X_train_kmeansClustered = kmeans.predict(X_train_PCA.loc[:,0:cutoff])\n",
        "    X_train_kmeansClustered = pd.DataFrame(data=X_train_kmeansClustered, index=X_train.index, columns=['cluster'])\n",
        "    \n",
        "    countByCluster_kMeans, countByLabel_kMeans, countMostFreq_kMeans, accuracyDF_kMeans, overallAccuracy_kMeans, accuracyByLabel_kMeans = analyzeCluster(X_train_kmeansClustered, y_train)\n",
        "    \n",
        "    overallAccuracy_kMeansDF.loc[n_clusters] = overallAccuracy_kMeans"
      ],
      "metadata": {
        "id": "7Bmuks4L6edi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot accuracy\n",
        "overallAccuracy_kMeansDF.plot()"
      ],
      "metadata": {
        "id": "uAjPu56E6izF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy by cluster\n",
        "accuracyByLabel_kMeans"
      ],
      "metadata": {
        "id": "4J7wshCQ6vDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View cluster labels\n",
        "X_train_kmeansClustered"
      ],
      "metadata": {
        "id": "uZXhrdZ366Ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy as the number of principal components varies"
      ],
      "metadata": {
        "id": "j_V3yN9l7BBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_clusters = 20\n",
        "n_init = 10\n",
        "max_iter = 300\n",
        "tol = 0.0001\n",
        "random_state = 2018\n",
        "\n",
        "kMeans_inertia = pd.DataFrame(data=[],index=[9, 49, 99, 199, 299, 399, 499, 599, 699, 783],columns=['inertia'])\n",
        "\n",
        "overallAccuracy_kMeansDF = pd.DataFrame(data=[],index=[9, 49, 99, 199, 299, 399, 499, 599, 699, 783], columns=['overallAccuracy'])\n",
        "\n",
        "for cutoffNumber in [9, 49, 99, 199, 299, 399, 499, 599, 699, 783]:\n",
        "    kmeans = KMeans(n_clusters=n_clusters, n_init=n_init, max_iter=max_iter, tol=tol, random_state=random_state)\n",
        "\n",
        "    cutoff = cutoffNumber\n",
        "    kmeans.fit(X_train_PCA.loc[:,0:cutoff])\n",
        "    kMeans_inertia.loc[cutoff] = kmeans.inertia_\n",
        "    X_train_kmeansClustered = kmeans.predict(X_train_PCA.loc[:,0:cutoff])\n",
        "    X_train_kmeansClustered = pd.DataFrame(data=X_train_kmeansClustered, index=X_train.index, columns=['cluster'])\n",
        "    \n",
        "    countByCluster_kMeans, countByLabel_kMeans, countMostFreq_kMeans, accuracyDF_kMeans, overallAccuracy_kMeans, accuracyByLabel_kMeans = analyzeCluster(X_train_kmeansClustered, y_train)\n",
        "    \n",
        "    overallAccuracy_kMeansDF.loc[cutoff] = overallAccuracy_kMeans"
      ],
      "metadata": {
        "id": "U6z7JGfT7Gcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overallAccuracy_kMeansDF.plot()"
      ],
      "metadata": {
        "id": "CXimj1oE7PlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy as the number of original dimensions varies"
      ],
      "metadata": {
        "id": "sP4FyH7l7cYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_clusters = 20\n",
        "n_init = 10\n",
        "max_iter = 300\n",
        "tol = 0.0001\n",
        "random_state = 2018\n",
        "\n",
        "kMeans_inertia = pd.DataFrame(data=[],index=[9, 49, 99, 199, 299, 399, 499, 599, 699, 783],columns=['inertia'])\n",
        "\n",
        "overallAccuracy_kMeansDF = pd.DataFrame(data=[],index=[9, 49, 99, 199, 299, 399, 499, 599, 699, 783], columns=['overallAccuracy'])\n",
        "\n",
        "for cutoffNumber in [9, 49, 99, 199, 299, 399, 499, 599, 699, 783]:\n",
        "    kmeans = KMeans(n_clusters=n_clusters, n_init=n_init, max_iter=max_iter, tol=tol, random_state=random_state)\n",
        "\n",
        "    cutoff = cutoffNumber\n",
        "    kmeans.fit(X_train.loc[:,0:cutoff])\n",
        "    kMeans_inertia.loc[cutoff] = kmeans.inertia_\n",
        "    X_train_kmeansClustered = kmeans.predict(X_train.loc[:,0:cutoff])\n",
        "    X_train_kmeansClustered = pd.DataFrame(data=X_train_kmeansClustered, index=X_train.index, columns=['cluster'])\n",
        "    \n",
        "    countByCluster_kMeans, countByLabel_kMeans, countMostFreq_kMeans, accuracyDF_kMeans, overallAccuracy_kMeans, accuracyByLabel_kMeans = analyzeCluster(X_train_kmeansClustered, y_train)\n",
        "    \n",
        "    overallAccuracy_kMeansDF.loc[cutoff] = overallAccuracy_kMeans"
      ],
      "metadata": {
        "id": "M9mLxfD87gAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overallAccuracy_kMeansDF.plot()"
      ],
      "metadata": {
        "id": "ROXQAxVb7l8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hierarchical clustering"
      ],
      "metadata": {
        "id": "7L5I5S6Q7xmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fastcluster\n",
        "from scipy.cluster.hierarchy import dendrogram, cophenet\n",
        "from scipy.spatial.distance import pdist\n",
        "\n",
        "cutoff = 99\n",
        "Z = fastcluster.linkage_vector(X_train_PCA.loc[:,0:cutoff], method='ward', metric='euclidean')\n",
        "Z_dataFrame = pd.DataFrame(data=Z, columns=['clusterOne','clusterTwo','distance','newClusterSize'])"
      ],
      "metadata": {
        "id": "NzTVtqlA7zkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z_dataFrame.iloc[:20]"
      ],
      "metadata": {
        "id": "2uxIlTEe74bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z_dataFrame.iloc[49980:]"
      ],
      "metadata": {
        "id": "fKFZEVKT77gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create clusters\n",
        "from scipy.cluster.hierarchy import fcluster\n",
        "\n",
        "distance_threshold = 160\n",
        "clusters = fcluster(Z, distance_threshold, criterion='distance')\n",
        "X_train_hierClustered = \\\n",
        "    pd.DataFrame(data=clusters,index=X_train_PCA.index,columns=['cluster'])"
      ],
      "metadata": {
        "id": "HfUjxQys8ArL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of distinct clusters: \", \\\n",
        "      len(X_train_hierClustered['cluster'].unique()))"
      ],
      "metadata": {
        "id": "5xZguCJH-Lml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "countByCluster_hierClust, countByLabel_hierClust, countMostFreq_hierClust, accuracyDF_hierClust, overallAccuracy_hierClust, accuracyByLabel_hierClust = analyzeCluster(X_train_hierClustered, y_train)\n",
        "\n",
        "print(\"Overall accuracy from hierarchical clustering: \", overallAccuracy_hierClust)"
      ],
      "metadata": {
        "id": "V34wtKFe-Qo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy by cluster for hierarchical clustering\")\n",
        "accuracyByLabel_hierClust"
      ],
      "metadata": {
        "id": "c2VcOsY6-Wk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_hierClustered[0:2000].to_csv(log_dir+'hierarchical_cluster_labels.tsv', sep = '\\t', index=False, header=False)"
      ],
      "metadata": {
        "id": "Ah0GiyVd-YyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DBSCAN"
      ],
      "metadata": {
        "id": "XRYswbE6-czi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "eps = 3\n",
        "min_samples = 5\n",
        "leaf_size = 30\n",
        "n_jobs = 4\n",
        "\n",
        "db = DBSCAN(eps=eps, min_samples=min_samples, leaf_size=leaf_size, \n",
        "            n_jobs=n_jobs)\n",
        "\n",
        "cutoff = 99\n",
        "X_train_PCA_dbscanClustered = db.fit_predict(X_train_PCA.loc[:,0:cutoff])\n",
        "X_train_PCA_dbscanClustered = \\\n",
        "    pd.DataFrame(data=X_train_PCA_dbscanClustered, index=X_train.index, \\\n",
        "                 columns=['cluster'])\n",
        "\n",
        "countByCluster_dbscan, countByLabel_dbscan, countMostFreq_dbscan, \\\n",
        "    accuracyDF_dbscan, overallAccuracy_dbscan, accuracyByLabel_dbscan \\\n",
        "    = analyzeCluster(X_train_PCA_dbscanClustered, y_train)\n",
        "\n",
        "overallAccuracy_dbscan"
      ],
      "metadata": {
        "id": "qO1d02fE-dno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Overall accuracy from DBSCAN: \",overallAccuracy_dbscan)"
      ],
      "metadata": {
        "id": "wgahKahW-gIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cluster results for DBSCAN\")\n",
        "countByCluster_dbscan"
      ],
      "metadata": {
        "id": "Wc2xrqoi-jhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_PCA_dbscanClustered"
      ],
      "metadata": {
        "id": "nO7pTwAX-mPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HDBSCAN"
      ],
      "metadata": {
        "id": "2SX1ysbN-rdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import hdbscan\n",
        "\n",
        "min_cluster_size = 30\n",
        "min_samples = None\n",
        "alpha = 1.0\n",
        "cluster_selection_method = 'eom'\n",
        "\n",
        "hdb = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size, min_samples=min_samples, alpha=alpha, cluster_selection_method=cluster_selection_method)\n",
        "\n",
        "cutoff = 10\n",
        "X_train_PCA_hdbscanClustered = hdb.fit_predict(X_train_PCA.loc[:,0:cutoff])\n",
        "\n",
        "X_train_PCA_hdbscanClustered = pd.DataFrame(data=X_train_PCA_hdbscanClustered, index=X_train.index, columns=['cluster'])\n",
        "\n",
        "countByCluster_hdbscan, countByLabel_hdbscan, countMostFreq_hdbscan, accuracyDF_hdbscan, overallAccuracy_hdbscan, accuracyByLabel_hdbscan = analyzeCluster(X_train_PCA_hdbscanClustered, y_train)"
      ],
      "metadata": {
        "id": "hstyObmW-tI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Overall accuracy from HDBSCAN: ', overallAccuracy_hdbscan)"
      ],
      "metadata": {
        "id": "nKBe4QX--3G1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Cluster results for HDBSCAN')\n",
        "countByCluster_hdbscan"
      ],
      "metadata": {
        "id": "X6R3iVu4_BCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_PCA_hdbscanClustered"
      ],
      "metadata": {
        "id": "18Ncb0lL_GR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "D96mltik_LV7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}