{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoencoders.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNX3uTzk5Ba4xyoFEPRMF5e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sml8648/Handson_unsupervised_learning/blob/main/autoencoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uSPaZYff9B3"
      },
      "outputs": [],
      "source": [
        "'''Main'''\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, time, re\n",
        "import pickle, gzip\n",
        "\n",
        "'''Data Viz'''\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "color = sns.color_palette()\n",
        "%matplotlib inline\n",
        "\n",
        "'''Data Prep and Model Evaluation'''\n",
        "from sklearn import preprocessing as pp\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.model_selection import StratifiedKFold \n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "\n",
        "'''Algos'''\n",
        "import lightgbm as lgb\n",
        "\n",
        "'''TensorFlow and Keras'''\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "K = keras.backend\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization, Input, Lambda\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.losses import mse, binary_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, sklearn\n",
        "print(f'sklearn {sklearn.__version__}')\n",
        "print(f'tensorflow {tf.__version__}')\n",
        "print(f'keras     {keras.__version__}')\n",
        "print(f'numpy.    {np.__version__}')"
      ],
      "metadata": {
        "id": "6HxLgSH7gQOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "1l1eNNKbgnJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if tf.test.gpu_device_name():\n",
        "    print('Default GPU Device : {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "    print('Please install GPU version of TF, if GPU is available.')"
      ],
      "metadata": {
        "id": "Q1Jc8kAGg5YF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "ppYwBHZUhat2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/sample_data/creditcard.csv')"
      ],
      "metadata": {
        "id": "mMDbwvpOhGXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataX = data.copy().drop(['Class','Time'],axis=1)\n",
        "dataY = data['Class'].copy()"
      ],
      "metadata": {
        "id": "kjW0L4n0heFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split into train and test"
      ],
      "metadata": {
        "id": "InWLfV7shocw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=0.33, random_state=2018, stratify=dataY)"
      ],
      "metadata": {
        "id": "KTdoKQtohqkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('mode.chained_assignment',None)\n",
        "\n",
        "featuresToScale = dataX.columns\n",
        "sX = pp.StandardScaler(copy=True, with_mean=True, with_std=True)\n",
        "X_train.loc[:,featuresToScale] = sX.fit_transform(X_train.loc[:,featuresToScale])\n",
        "X_test.loc[:,featuresToScale] = sX.transform(X_test.loc[:,featuresToScale])"
      ],
      "metadata": {
        "id": "79MJbb_4h1mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_AE, X_test_AE = X_train.copy(), X_test.copy()"
      ],
      "metadata": {
        "id": "wVgupTAnjeBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define evaluation function and plotting function"
      ],
      "metadata": {
        "id": "sh0iH_U_jp-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def anomalyScores(originalDF, reducedDF):\n",
        "    loss = np.sum((np.array(originalDF) - np.array(reducedDF))**2, axis=1)\n",
        "    loss = pd.Series(data=loss, index=originalDF.index)\n",
        "    loss = (loss-np.min(loss))/(np.max(loss)-np.min(loss))\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "Da4jsFZ_jvLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotResults(trueLabels, anomalyScores, returnPreds = False):\n",
        "    preds = pd.concat([trueLabels, anomalyScores], axis=1)\n",
        "    preds.columns = ['trueLabel', 'anomalyScore']\n",
        "    precision, recall, thresholds = \\\n",
        "        precision_recall_curve(preds['trueLabel'], \n",
        "                               preds['anomalyScore'])\n",
        "    average_precision = average_precision_score( \n",
        "                        preds['trueLabel'], preds['anomalyScore'])\n",
        "    \n",
        "    plt.step(recall, precision, color='k', alpha=0.7, where='post')\n",
        "    plt.fill_between(recall, precision, step='post', alpha=0.3, color='k')\n",
        "\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    \n",
        "    plt.title('Precision-Recall curve: Average Precision = \\\n",
        "        {0:0.2f}'.format(average_precision))\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(preds['trueLabel'], \n",
        "                                     preds['anomalyScore'])\n",
        "    areaUnderROC = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, color='r', lw=2, label='ROC curve')\n",
        "    plt.plot([0, 1], [0, 1], color='k', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic: Area under the \\\n",
        "        curve = {0:0.2f}'.format(areaUnderROC))\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    \n",
        "    if returnPreds==True:\n",
        "        return preds, average_precision"
      ],
      "metadata": {
        "id": "VmgROLBYkCoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model One\n",
        "<h2> Two layer complete autoencoder with linear activation"
      ],
      "metadata": {
        "id": "q2hZZ5YVkSU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "-b7NP5MVkXR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units=29, activation='linear',input_dim=29))\n",
        "model.add(Dense(units=29, activation='linear'))"
      ],
      "metadata": {
        "id": "eKrTp2g0ka3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='mean_squared_error', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "cOtOC1E3kkqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "history = model.fit(x=X_train_AE, y=X_train_AE,\n",
        "                    epochs=num_epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    shuffle=True,\n",
        "                    validation_data=(X_train_AE, X_train_AE),\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "id": "B57-vidOkrPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate on Test Set"
      ],
      "metadata": {
        "id": "U68-yJz9lU4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test, verbose=1)\n",
        "anomalyScoresAE = anomalyScores(X_test, predictions)\n",
        "preds = plotResults(y_test, anomalyScoresAE, True)\n",
        "model.reset_states()"
      ],
      "metadata": {
        "id": "m4JAJpGxlYRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10 runs - we will capture mean of average precision\n",
        "\n",
        "test_scores = []\n",
        "for i in range(0,10):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(units=29, activation='linear',input_dim=29))\n",
        "\n",
        "    model.add(Dense(units=29, activation='linear'))\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='mean_squared_error',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    num_epochs = 10\n",
        "    batch_size = 32\n",
        "\n",
        "    history = model.fit(x=X_train_AE, y=X_train_AE,\n",
        "                        epochs=num_epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=True,\n",
        "                        validation_data=(X_train_AE, X_train_AE),\n",
        "                        verbose=1)\n",
        "    \n",
        "    predictions = model.predict(X_test, verbose=1)\n",
        "    anomalyScoresAE = anomalyScores(X_test, predictions)\n",
        "    preds, avgPrecision = plotResults(y_test, anomalyScoresAE, True)\n",
        "    test_scores.append(avgPrecision)\n",
        "    model.reset_states()\n",
        "\n",
        "print(f'Mean average precision over 10 runs: {np.mean(test_scores)}')\n",
        "[round(x,4) for x in test_scores]"
      ],
      "metadata": {
        "id": "Z3juIGdVlwH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Two\n",
        "<h3> Two layer undercomplete autoencoder with linera activation"
      ],
      "metadata": {
        "id": "wJ6Pod21oUDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "vharf6qtoZUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_scores = []\n",
        "for i in range(0,10):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(units=20, activation='linear',input_dim=29))\n",
        "\n",
        "    model.add(Dense(units=29, activation='linear'))\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='mean_squared_error',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    num_epochs = 10\n",
        "    batch_size = 32\n",
        "\n",
        "    history = model.fit(x=X_train_AE, y=X_train_AE,\n",
        "                        epochs=num_epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=True,\n",
        "                        validation_data=(X_train_AE, X_train_AE),\n",
        "                        verbose=1)\n",
        "    \n",
        "\n",
        "    predictions = model.predict(X_test, verbose=1)\n",
        "    anomalyScoresAE = anomalyScores(X_test, predictions)\n",
        "    preds, avgPrecision = plotResults(y_test, anomalyScoresAE, True)\n",
        "    test_scores.append(avgPrecision)\n",
        "    model.reset_states()\n",
        "\n",
        "print(f\"Mean average precision over 10 runs: {round(np.mean(test_scores),4)}\")\n",
        "[round(x,4) for x in test_scores]"
      ],
      "metadata": {
        "id": "QxMrYwHmogFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Three\n",
        "<h3> Three layer undercomplete autoencoder with linear activation"
      ],
      "metadata": {
        "id": "VlpxEnnN2SeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "TKLoa98Y2Zu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10 runs - We will capture mean of average precision\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "test_scores = []\n",
        "for i in range(0,10):\n",
        "    # Call neural network API\n",
        "    model = Sequential()\n",
        "\n",
        "    # Apply linear activation function to input layer\n",
        "    # Generate first hidden layer with 27 nodes\n",
        "    # Generate second hidden layer with 28 nodes\n",
        "    model.add(Dense(units=28, activation='linear',input_dim=29))\n",
        "    model.add(Dense(units=27, activation='linear'))\n",
        "\n",
        "    # Apply linear activation function to second hidden layer\n",
        "    # Generate output layer with 29 nodes\n",
        "    model.add(Dense(units=29, activation='linear'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='mean_squared_error',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    num_epochs = 10\n",
        "    batch_size = 32\n",
        "\n",
        "    history = model.fit(x=X_train_AE, y=X_train_AE,\n",
        "                        epochs=num_epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=True,\n",
        "                        validation_data=(X_train_AE, X_train_AE),\n",
        "                        verbose=1)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    predictions = model.predict(X_test, verbose=1)\n",
        "    anomalyScoresAE = anomalyScores(X_test, predictions)\n",
        "    preds, avgPrecision = plotResults(y_test, anomalyScoresAE, True)\n",
        "    test_scores.append(avgPrecision)\n",
        "    model.reset_states()\n",
        "\n",
        "print(f\"Mean average precision over 10 runs: {round(np.mean(test_scores),4)}\")\n",
        "[round(x,4) for x in test_scores]"
      ],
      "metadata": {
        "id": "q2dZnagJ2dgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Result\n",
        "print(f'Mean average precision over 10 runs:   {round(np.mean(test_scores),4)}')\n",
        "print(f'Coefficient of variation over 10 runs: {round(np.std(test_scores)/np.mean(test_scores),4)}')\n",
        "[round(x,4) for x in test_scores]"
      ],
      "metadata": {
        "id": "XCdlmsmF2jTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Four\n",
        "<h3> Four layer undercomplete autoencoder with ReLu activation"
      ],
      "metadata": {
        "id": "f9apJ7X92wM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "fbyNLJS021DE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10 runs - We will capture mean of average precision\n",
        "test_scores = []\n",
        "for i in range(0,10):\n",
        "    # Call neural network API\n",
        "    model = Sequential()\n",
        "\n",
        "    # Apply ReLu throughout\n",
        "    # Generate first hidden layer with 27 nodes\n",
        "    # Generate second hidden layer with 22 nodes\n",
        "    model.add(Dense(units=27, activation='relu',input_dim=29))\n",
        "    model.add(Dense(units=22, activation='relu'))\n",
        "\n",
        "    # Apply ReLu throughout\n",
        "    # Generate third hidden layer with 27 nodes\n",
        "    # Generate output layer with 29 nodes\n",
        "    model.add(Dense(units=27, activation='relu'))\n",
        "    model.add(Dense(units=29, activation='relu'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='mean_squared_error',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    num_epochs = 10\n",
        "    batch_size = 32\n",
        "\n",
        "    history = model.fit(x=X_train_AE, y=X_train_AE,\n",
        "                        epochs=num_epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=True,\n",
        "                        validation_data=(X_train_AE, X_train_AE),\n",
        "                        verbose=1)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    predictions = model.predict(X_test, verbose=1)\n",
        "    anomalyScoresAE = anomalyScores(X_test, predictions)\n",
        "    preds, avgPrecision = plotResults(y_test, anomalyScoresAE, True)\n",
        "    test_scores.append(avgPrecision)\n",
        "    model.reset_states()\n",
        "\n",
        "print(f\"Mean average precision over 10 runs: {round(np.mean(test_scores),4)}\")\n",
        "[round(x,4) for x in test_scores]"
      ],
      "metadata": {
        "id": "2Luq2C1723cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Result\n",
        "print(f'Mean average precision over 10 runs:   {round(np.mean(test_scores),4)}')\n",
        "print(f'Coefficient of variation over 10 runs: {round(np.std(test_scores)/np.mean(test_scores),4)}')\n",
        "[round(x,4) for x in test_scores]"
      ],
      "metadata": {
        "id": "yxZziw0529x5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Five\n",
        "<h3> Two layer overcomplete autoencoder with linear activation"
      ],
      "metadata": {
        "id": "KIO9MOVR3G65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "EiM4biVu3Lhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10 runs - We will capture mean of average precision\n",
        "test_scores = []\n",
        "for i in range(0,10):\n",
        "    # Call neural network API\n",
        "    model = Sequential()\n",
        "\n",
        "    # Apply linear activation function throughout\n",
        "    # Generate first hidden layer with 40 nodes\n",
        "    model.add(Dense(units=40, activation='linear',input_dim=29))\n",
        "\n",
        "    # Generate output layer with 29 nodes\n",
        "    model.add(Dense(units=29, activation='linear'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='mean_squared_error',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    num_epochs = 10\n",
        "    batch_size = 32\n",
        "\n",
        "    history = model.fit(x=X_train_AE, y=X_train_AE,\n",
        "                        epochs=num_epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=True,\n",
        "                        validation_data=(X_train_AE, X_train_AE),\n",
        "                        verbose=1)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    predictions = model.predict(X_test, verbose=1)\n",
        "    anomalyScoresAE = anomalyScores(X_test, predictions)\n",
        "    preds, avgPrecision = plotResults(y_test, anomalyScoresAE, True)\n",
        "    test_scores.append(avgPrecision)\n",
        "    model.reset_states()\n",
        "    \n",
        "print(f\"Mean average precision over 10 runs: {round(np.mean(test_scores),4)}\")\n",
        "[round(x,4) for x in test_scores]"
      ],
      "metadata": {
        "id": "9-gKe74b3Q2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Result\n",
        "print(f'Mean average precision over 10 runs:   {round(np.mean(test_scores),4)}')\n",
        "print(f'Coefficient of variation over 10 runs: {round(np.std(test_scores)/np.mean(test_scores),4)}')\n",
        "[round(x,4) for x in test_scores]"
      ],
      "metadata": {
        "id": "Ki0id4Ja3WJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Six\n",
        "<h3> Two layer overcomplete autoencoder with linear activation and dropout"
      ],
      "metadata": {
        "id": "ZUQtchCg3eup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "tf.random.seed(42)"
      ],
      "metadata": {
        "id": "xfNMiKez3lCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10 runs - We will capture mean of average precision\n",
        "test_scores = []\n",
        "for i in range(0,10):\n",
        "    # Call neural network API\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(units=40, activation='linear',input_dim=29))\n",
        "    model.add(Dropout(0.10))\n",
        "\n",
        "    # Generate output layer with 29 nodes\n",
        "    model.add(Dense(units=29, activation='linear'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='mean_squared_error',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    num_epochs = 10\n",
        "    batch_size = 32\n",
        "\n",
        "    history = model.fit(x=X_train_AE, y=X_train_AE,\n",
        "                        epochs=num_epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=True,\n",
        "                        validation_data=(X_train_AE, X_train_AE),\n",
        "                        verbose=1)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    predictions = model.predict(X_test, verbose=1)\n",
        "    anomalyScoresAE = anomalyScores(X_test, predictions)\n",
        "    preds, avgPrecision = plotResults(y_test, anomalyScoresAE, True)\n",
        "    test_scores.append(avgPrecision)\n",
        "    model.reset_states()\n",
        "\n",
        "print(f\"Mean average precision over 10 runs: {round(np.mean(test_scores),4)}\")\n",
        "[round(x,4) for x in test_scores]"
      ],
      "metadata": {
        "id": "2dgKca_D3oN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Result\n",
        "print(f'Mean average precision over 10 runs:   {round(np.mean(test_scores),4)}')\n",
        "print(f'Coefficient of variation over 10 runs: {round(np.std(test_scores)/np.mean(test_scores),4)}')\n",
        "[round(x,4) for x in test_scores]"
      ],
      "metadata": {
        "id": "BF3YNNuT3ydA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Wh6WCfuB34RH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}